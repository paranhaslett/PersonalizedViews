%@+leo-ver=4-thin
%@+node:paran.20140515173914.6982:@shadow ./fmpp/Tex/Thesis/Chapters/Background.tex
%@@color
%@@language latex
\chapter{Background}

\section{Version Control Systems}
%@<<VersionControlSystems>>
%@+node:paran.20140516082812.1939:<<VersionControlSystems>>
There are a number of reasons why we might want to use a version control system.

Version control systems are a way to keep old revisions of a document backed up so that if you ever need to revisit a previous revision you can always access it.
Repositories also allow people to work on the same document at the same time.
Most version control systems work better on plain text documents such as such as source code written in a plain text programming language.
Version control is a way to maintain divergent code.


\subsection{Before version control}
%@<<Dawn of Time>>
%@+node:paran.20140515173914.6999:<<Dawn of Time>>
Before version control the only way to keep a backup of a file was to copy the code and save it into a different file on the file system.
In \"Pro Git\" Caldon makes the observation that if you have no source control the best that you can do is to manually back up items on the file system under folders with a specific date so that you can go back and visit a previous revision.  A problem that source code revision addresses is that when a backup is made many files are duplicated verbatim.  The needlessly duplicated files waste file resources.
%@nonl
%@-node:paran.20140515173914.6999:<<Dawn of Time>>
%@nl

\subsection{Revision Control System (RCS)}
%@<<RCS>>
%@+node:paran.20140515173914.6995:<<RCS>>
RCS was one of the original versioning systems 

Instead of keeping multiple copies of the file that had changed it kept the original file and any of the subsequent change sets.
This meant that any revision could be revisited and changed.

By recording both the original file and the change sets the amount of disk space used was reduced. 

It allowed a small amount of collaboration by locking files that had been checked out.
This ensured that the checked out file could only be edited by one person at a time.

This is a limitation which would not suit companies that have many developers working on the same source code.  
There has to be a lot of communication and agreement about who is working on what.
%@nonl
%@-node:paran.20140515173914.6995:<<RCS>>
%@nl

\subsection{Merging two documents}
%@<<Merging>>
%@+node:paran.20140515173914.6994:<<Merging>>

If not regularly merged is is possible for the source code to diverge greatly and it becomes harder and harder to reconcile.
 According to Bertino it is possible to keep a smaller more easily deployed repository by evaluating what is necessary and what is unnecessary \cite{Bertino2012}. Although Bertino refers to unnecessary files this premise may also be applicable for the smaller blocks of code we are interested in. This suggests that maintaining a record about what is relevant and what is irrelevant may have some benefit. Version control still can have merge conflict issues. These issues have a far greater chance of occurring if there is a dramatic change such as refactoring
 
\subsubsection{Manual Merging}
%@<<Manual Merging>>
%@+node:paran.20140522084554.1932:<<Manual Merging>>


%@+at
% Manual merge Example
%@-at
%@@c
%@nonl
%@-node:paran.20140522084554.1932:<<Manual Merging>>
%@nl

\subsubsection{Automatic Merging}
%@<<Automatic Merging>>
%@+node:paran.20140522084554.1933:<<Automatic Merging>>
If there is a three way merge it is possible for the computer to calculate the merge independently provided that there are no merge conflicts.
To do 3 way merging requires 3 different revisions are required, the changes you have made, the changes made by others, and the revision that is common to them both.


%@+at
% Diagram showing that how merging could be done automatically
% if there is a change in your code but no change in others code automatic
% if there is a change in others code but not yours
% 
%@-at
%@@c
%@nonl
%@-node:paran.20140522084554.1933:<<Automatic Merging>>
%@nl
%@-node:paran.20140515173914.6994:<<Merging>>
%@nl

\subsection{Centralised version control}
%@<<Centralised Version control>>
%@+node:paran.20140515173914.6993:<<Centralised Version control>>
Still had the model of a central repository everyone needed to consistent
similar to RCS in that you could still check the file out but it was not as necessary to lock the file
it was possible to look at the differences between the files and then automatically merge when it was possible
%@nonl
%@-node:paran.20140515173914.6993:<<Centralised Version control>>
%@nl

\subsection{Distributed version control}
%@<<Distributed Version control>>
%@+node:paran.20140515173914.6992:<<Distributed Version control>>
The need to be connected to a central system solved a lot of issues but often had a large overhead.  

%@+at 
%@nonl
% mobile access
%@-at
%@@c 


\subsubsection{Using git}
%@<<Git>>
%@+node:paran.20140515173914.6991:<<Git>>
Git is a repository which is used mostly for software development.

This is done by combining all the changes to a document in a process called merging. 
In order to merge, any change an editor makes needs to be recorded and compared against the changes made by other editors.
If it is possible for those changes to co-exist then the changes will be made.
An example of changes that are considered to be able to co-exist is if all editors change a different part of the document.
If it is not possible for those changes to co-exist then there is a \"merge conflict\".
An example of a merge conflict is if any two changes on the document overlap with different values.
Before any merging can be done all of the changes need to be determined

In GIT there are a number of changes recorded for a file differences,  A file could be added, deleted, moved, copied, or modified.  The same is not true of changes within the file with only insert, delete, and modify being available.
%@nonl
%@-node:paran.20140515173914.6991:<<Git>>
%@nl
%@nonl
%@-node:paran.20140515173914.6992:<<Distributed Version control>>
%@nl
%@nonl
%@-node:paran.20140516082812.1939:<<VersionControlSystems>>
%@nl

\section{Longest Common Subsequence}
%@<<LCS>>
%@+node:paran.20140516082812.1952:<<LCS>>
There are a number of issues in computer science that can be resolved by a longest common subsequence algorithm.
It is very good at finding the differences between two different sets of ordered information.

%@+at
% look into other uses for LCS
%@-at
%@@c

\subsection{Example}
%@<<Example of Longest common subsequence>>
%@+node:paran.20140516082812.1953:<<Example of Longest common subsequence>>
One method of discovering what has changed is to find the longest common subsequence (LCS).
A simplified example of finding the longest common subsequence is:

Imagine we have have two similar sentences that we want to compare with each other.  
We would like to know what is the same and what is different.
A longest common subsequence for the sentences would contain a list of all the characters that are the same and in the same order
So for the following sentences

\begin{verbatim}

"The quick brown fox jumps over the lazy dog"

"The rapid brown fox vaults the lazy dog"

\end{verbatim}
A longest common subsequence would be
\begin{verbatim}
"The ","i"," brown fox ","v"," the lazy dog"
\end{verbatim}
The letters that are missing from the LCS differ between the sentences.
It is possible for a comparison to have multiple LCSs.
%@nonl
%@-node:paran.20140516082812.1953:<<Example of Longest common subsequence>>
%@nl

\subsection{Difference strategies}
%@<<Git difference strategies>>
%@+node:paran.20140516082812.1954:<<Git difference strategies>>
There are a number of ways that the longest common subsequences
Git uses the following algorithms to find the LCS.

%@<<Myers>>
%@+node:paran.20140516082812.1955:<<Myers>>
\subsection{Myers}

%@-node:paran.20140516082812.1955:<<Myers>>
%@nl

%@<<Patience>>
%@+node:paran.20140516082812.1956:<<Patience>>
\subsection{Patience}
The patience algorithm instead of figuring out the longest common subsequence directly uses the longest increasing subsequence.
when this is used with line numbers form source code the longest common subsequence can be established.

bran Cohen

because of the way a patience 

Before the act
%@+at
% from the patience game
% need references
%@-at
%@@c 
%@-node:paran.20140516082812.1956:<<Patience>>
%@nl

%@<<Histogram>>
%@+node:paran.20140516082812.1957:<<Histogram>>
\subsection{Histogram}
A Histogram difference strategy is very similar to a patience algorithm
Instead of looking at just the unique lines between any two subsets however it can examine lines that there are multiple copies of 
%@nonl
%@-node:paran.20140516082812.1957:<<Histogram>>
%@nl
%@-node:paran.20140516082812.1954:<<Git difference strategies>>
%@nl

\subsection{The problem with LCS}
%@<<The problem with LCS>>
%@+node:paran.20140516082812.1958:<<The problem with LCS>>
\section{The problem with longest common subsequence}
There is still a problem with longest common subsequence. It does not notice changes of order in a document.  For example if we were to take the following two sentences:

\begin{verbatim}

"The quick brown fox jumps over the lazy dog"

"The lazy brown dog jumps over the quick fox"

\end{verbatim}

The longest common subsequence of this would be

\begin{verbatim}
"The \"," brown ","o"," jumps over the ","o"
\end{verbatim}

Without further analyzing the changes it is possible to conclude that instead of swapping certain words that:

\begin{verbatim}
"quick" transforms into "lazy"
"f" transforms into "d"
\"x\" transforms into \"g\"
\"lazy d\" transforms into \"quick f\"
\"g\" transforms into \"x\"
\end{verbatim}

What this thesis aims to do is to more accurately portray these changes.
In order to do this we require some information about the structure of the document.
For the above example if the computer was aware that the sentence was structured into words rather than characters the result would have been slightly different.

\begin{verbatim}
\"The \",?,\" brown \",?,\"jumps \", \"over \", \"the \",?,?
\end{verbatim}

in this situation in becomes easier to recognize that words have been swapped by comparing each of the changes with each other.  

\begin{verbatim}
\"quick \" transforms into \"lazy \" matches \"lazy\" transforms into \"quick\"
\"fox \" transforms into \"dog\" matches \"dog\" transforms into \"fox\" 
\end{verbatim}

The English language is also far too complex to notice anything that is more basic than a word for word swap.
There are words and sentences that have similar meanings but are spelled and structured differently.
%@nonl
%@-node:paran.20140516082812.1958:<<The problem with LCS>>
%@nl

\subsection{How LCS is used in differencing tools}
%@<<How diffs use LCS>>
%@+node:paran.20140516082812.1959:<<How diffs use LCS>>
\section{How most difference tools use LCS}
The above is a simplified illustration of how general LCS works.
How most difference tools use LCS is quite different.
Most difference tools rather than comparing on a character by character difference compares line of text with each other.
Often to speed up the differencing process each line is assigned a hash code depending on its contents. 
This means that the differencing tool can work much faster as it does not need to compare each character in the line but can compare hash codes instead.
In the source code for many programming languages the white space is not relevant so many diff tools have the option of ignoring the whitespace and only comparing the code.
This has an impact on the hash codes for each line as the hash code needs to be generated from the text rather than the white spaces in the code.
%@+at
% Remember to say something white space
% and regular expression differences
% 
%@-at
%@@c
%@nonl
%@-node:paran.20140516082812.1959:<<How diffs use LCS>>
%@nl
 
 


%@-node:paran.20140516082812.1952:<<LCS>>
%@nl

\section{JDime}
%@<<JDime>>
%@+node:paran.20140516082812.1942:<<JDime>>
Part of the inspiration for this tool come from JDime



%@<<What Jdime can be used for>>
%@+node:paran.20140516082812.1943:<<What Jdime can be used for>>
JDime is useful for merging two different change sets. 
JDime can be used to compare two different sets of Java source codes which have been refactored and to produce a copy common to them both.  
%@nonl
%@-node:paran.20140516082812.1943:<<What Jdime can be used for>>
%@nl

%@<<How Jdime works>>
%@+node:paran.20140516082812.1961:<<How Jdime works>>
JDime instead of testing against a source code repository test against files in the system under the base, left and right directories.
While this may be useful in quickly being able to show what JDime is able to achieve it requires that the inputs need to be previously extracted from a repository into the file system.

Before doing any calculations, Jdime runs a regular text merge over the source code.  
If the regular text merge has conflicts then JDime determines if sections of the source code need to be in a particular order or could be in any order.
What then happens depends on if order is required in the section of code JDime is examining.
%@nonl
%@-node:paran.20140516082812.1961:<<How Jdime works>>
%@nl

%@<<Testing Jdimes suitability>>
%@+node:paran.20140516082812.1962:<<Testing Jdimes suitability>>
In order to examine how Jdime works a test handler was written.
The test handler sets up some java source code to be used by JDime in base, left and right directories.
In order to test JDime it is necessary to cause the initial text comparison to incorrectly label as a conflict.
A way to get a lot of text conflicts between two pieces of code that are equivalent when they run is to change the order of the methods.
Although the methods are in different order the programs are still \"functionally equivalent\".
The order of the methods where scrambled in files in the base, left and right directories.
%@nonl
%@-node:paran.20140516082812.1962:<<Testing Jdimes suitability>>
%@nl





 







%@-node:paran.20140516082812.1942:<<JDime>>
%@nl
 
 


%@-node:paran.20140515173914.6982:@shadow ./fmpp/Tex/Thesis/Chapters/Background.tex
%@-leo
