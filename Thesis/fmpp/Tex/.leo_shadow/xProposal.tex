%@+leo-ver=4-thin
%@+node:hasletpara.20130905084546.1629:@shadow ./fmpp/Tex/Proposal.tex
%@@language latex
\documentclass[12pt]{CRPITStyle} 
%\usepackage{epsfig} % Packages to use if you wish
%\usepackage{lscape} % 
\usepackage[authoryear]{natbib}
\usepackage{graphicx}
\renewcommand{\cite}{\citep}
\pagestyle{empty}
\thispagestyle{empty}
\hyphenation{roddick}
\onecolumn
\begin{document}

%@<<title>>
%@+node:hasletpara.20130905084546.1630:<<title>>
\title{Thesis Proposal}
\author{Paran D Haslett (300274241)}
\affiliation{School of Engineering and Computer Science\\
Room C168C\\
Cotton Building\\
Victoria University of Wellington\\
Gate 6, Kelburn Parade\\
Wellington, \\
Email :~{\tt Paran.Haslett@ecs.vuw.ac.nz}}
%@nonl
%@-node:hasletpara.20130905084546.1630:<<title>>
%@nl
\maketitle

%@<<abstract>>
%@+node:hasletpara.20130905084546.1631:<<abstract>>
\begin{abstract}
When collaborating on a project there are times when the code diverges. This could be due to refactoring or code being reused in another project. It could even be due to throwaway code or code used for debugging. This could at times also involve how the structure of the program is presented or the variable and method names that are being used. This is especially true if there is a piece of functionality that you wish to work on that differs from what everyone else is working on. In these cases you may need to refactor the code to best suit your changes before you apply them. The ability to have a separate view which although functionally equivalent to other views can present the code in a different form in these situation would be valuable. It enables the programmer to refactor or change the code with minimal impact on others. If the relationships between views are maintained it also could better recognise changes that need to be communicated to other views or branches.
\end{abstract}
\vspace{.1in}

\noindent {\em Keywords: Personal annotations, Collaboration, Multiple views, Semantic Merge} 
%@nonl
%@-node:hasletpara.20130905084546.1631:<<abstract>>
%@nl

%@<<body>>
%@+node:hasletpara.20130905084546.1632:<<body>>
%@+others
%@+node:hasletpara.20130905084546.1650:Introduction
\section{Introduction}
There are some issues that arise in Software Development when code diverges from a point. This divergence could be caused for a number of reasons including adding new functionality, refactoring, or code being reused. When source code diverges it could be helpful to retain relationships between the code that has diverged. In keeping these relationships it may be useful to identify source code that has the same intention and source code that is only relevant within a particular branch or view. 

%@+others
%@+node:hasletpara.20130905084546.1662:The problem
%@+others
%@+node:hasletpara.20130905084546.1667:refactoring
\subsection{Refactoring}
A common concern with coding is the need to periodically refactor the code. According to Fowler et al. the main time for refactoring is when new functionality is added \cite{Fowler1999}. Similarly according to Kerievsky some of the motivations for refactoring include adding more code and understanding existing code \cite{Kerievsky2004}. As adding more functionality is one of the motivations for refactoring let us consider what happens in a multi-developer environment. Two developers could have different view on what is considered an appropriate refactoring. This is especially true if they need to add different functionality from each other. 


A simple example is illustrated as follows:
\begin{verbatim}
public TempConv() {
  %@  <<tempConv>>
  %@+node:hasletpara.20131120092329.1771:<<tempConv>>
  Scanner keyboard = new Scanner(System.in);
  System.out.println("Enter the temperature in Celsius");
  int celsius = keyboard.nextInt();
  System.out.println("Degrees Fahrenheit is approx " + (celsius * 2 + 30) );
  keyboard.close();
  %@nonl
  %@-node:hasletpara.20131120092329.1771:<<tempConv>>
  %@nl
}
\end{verbatim}

Refactoring this code depends on what functionality you need to add. One developer may recognize that conversion from Celsius may be used several times throughout the code and so extract the calculations as a separate method as follows:

\begin{verbatim}
public TempConv() {
  %@  <<tempConv2>>
  %@+node:hasletpara.20131120092329.1772:<<tempConv2>>
  Scanner keyboard = new Scanner(System.in);
  System.out.println("Enter the temperature in Celsius");
  int celsius = keyboard.nextInt();
  System.out.println("Degrees Fahrenheit is approx " + celsiusToFahrenheit(celsius));
  keyboard.close();
  %@nonl
  %@-node:hasletpara.20131120092329.1772:<<tempConv2>>
  %@nl
}

public int celsiusToFahrenheit(int celsius){
  %@  <<celsiusToFahrenheit>>
  %@+node:hasletpara.20131120092329.1773:<<celsiusToFahrenheit>>
  return celsius * 2 + 30;
  %@nonl
  %@-node:hasletpara.20131120092329.1773:<<celsiusToFahrenheit>>
  %@nl
}
\end{verbatim}

This change, in spite of producing the same output as the first, provides a number of advantages. Firstly if other programs need to convert from Celsius to Fahrenheit the new method can easily be reused. Secondly since the calculation is a crude estimation it becomes a lot clearer where the code needs to be changed to improve the formula. The ability to add a method that clearly indicates that the calculation is from Celsius to Fahrenheit helps with the readability of the code. There are also disadvantages with doing this refactoring however. If we do not care about conversion between Celsius and Fahrenheit the refactoring simply adds to the amount of code we need to wade through before understanding what the code does. An alternate way of refactoring is as follows:

\begin{verbatim}
public TempConv(){
  %@  <<tempConv3>>
  %@+node:hasletpara.20131120092329.1774:<<tempConv3>>
  Scanner keyboard = new Scanner(System.in);
  System.out.println("Enter the temperature in Celsius");
  int celsius = keyboard.nextInt();
  int celsiusToFahrenheit = celsius *2 + 30;
  System.out.println("Degrees Fahrenheit is approx " + celsiusToFahrenheit);
  keyboard.close();
  %@nonl
  %@-node:hasletpara.20131120092329.1774:<<tempConv3>>
  %@nl
}
\end{verbatim}

While this again expresses the same functionality as the code above it has not created a new method to do so. This has some of the same advantages. It separates and identifies the formula to convert between Celsius and Fahrenheit. It also uses less code to express this separation than forming a new method. It does not expose the conversion formula outside this method to be used by other calculations however.

As the value of a particular refactoring appears to depend on what is trying to be achieved it is very hard to claim that one refactoring is better than another. It depends entirely on the wider context of the intention for the refactoring, in this case the level of access required for the approximation to convert Celsius to Fahrenheit.

Although this was a simple example it is easy to imagine a case where a much larger refactoring process is undertaken. In such circumstances a merge becomes difficult. 
%@-node:hasletpara.20130905084546.1667:refactoring
%@+node:hasletpara.20130905084546.1664:Differences in understanding code
\subsection{Differences in how code is understood}
Another reason that Kerievsky claims for refactoring code is to better understand it \cite{Kerievsky2004}. The very act of going through the source code and reprocessing it in a clearer form can help with the understanding of it. This would suggest that either developers tend to leave code in a difficult to understand state or that different developers understand things differently.
Kerievsky also relates a tale about how the lack of knowledge of patterns making a particular refactoring look a lot more complex \cite{Kerievsky2004}. The different perspectives meant that the programmer he refers to as John having a differing opinion that the refactored code was not an improvement. This shows that it is not just different functionality that influences the need to refactor but sometime the knowledge and experience of the developers themselves. It is often the case that two developers could have different views about what is an appropriate refactoring. This could be because each person brings different skills, notices different issues and has a preferred way of visualizing a problem and solution.

%@-node:hasletpara.20130905084546.1664:Differences in understanding code
%@+node:hasletpara.20131104103532.1627:Multiple developers
\subsection{Working on large projects with multiple developers}
Perry claimed that there are not adequate tools to use with projects with multiple developers \cite{Perry2001}. Whilst a lot of differences between two different versions of source code can be already merged by source control, refactoring often involves larger structural changes. According to Freese these larger changes can lead to merge problems if a traditional text difference approach is used \cite{freese2007operation}. Digg et al. have identified that merging after refactoring causes problems with some SCM systems and that tools that are more aware of semantic changes are necessary \cite{Dig2008}. This has lead to the development of smarter merge technology being used to compare code. The simplest of these being hunting for regular expressions so that white-space is not a factor during merging. This is already a feature on many merge tools. Some more complicated examples of this are presented by Le{\ss}enich and Apel who both identify in addition to text based merging both structured and semi-structured approaches to merging \cite{LeBenich2012} \cite{Apel2011}. Although Le{\ss}enich briefly talks about using GIT with a semi structured merge they have named ``JDime'' there are some interesting features of distributed version control system that have not been explored.

\begin{center}
\includegraphics[scale=0.5]{git-diag}
\end{center}

In the above diagram we have a situation where two branches have diverged in GIT and we would like to merge only the changes that would have a \emph{functional difference}. We do not want to merge differences in branch one if they have been refactored but still perform the same function as branch two.  There has been some success in using JDime to achieve this.  JDime can do a refactoring based merge on the head of branch one with the head of branch two.  As a refactoring merge is done from the head of each branch the code may have diverged a great distance.  There may be benefits in instead doing a lot of micro refactoring merges, one for each check-in. As code has not diverged as far for a single check-in, the conflicts could be less severe and easier to automatically resolve. 

Let us also consider if both branches in a merge have been refactored or dramatically changed. During a merge it would be advisable to favour one set of changes over another and then work through the conflicts. While this might be appropriate there could be times when further changes need to be made on the branch with the unfavoured refactoring. This would be true if there were periodic updates of functionality. When the next merge occurs for the diverging branches we could find ourselves having to resolve similar merge conflicts. 



%@-node:hasletpara.20131104103532.1627:Multiple developers
%@-others
%@nonl
%@-node:hasletpara.20130905084546.1662:The problem
%@-others
%@-node:hasletpara.20130905084546.1650:Introduction
%@+node:hasletpara.20130905084546.1653:Related Work
\section{Related Work}
The ability to have two differently refactored views of a functionally equivalent piece of source code is influenced by a number of software practices and tools. Some of these allow different views to interact by requiring them to adhere to certain standards and some are more flexible. The challenge is to allow flexibility while communicating what a change to one view should mean to the other. 

%@+others
%@+node:hasletpara.20130910094414.1578:Archetecture
\subsection{Formal architecture and design}
An approach that has been tried in an effort to manage different points of view is by ensuring that the source code has a strictly agreed upon architecture.  The architecture could change dramatically when refactoring in order to add further functionality. According to Tang et al. a reason you might want to change an architecture is that is often hard to determine an appropriate design before something is implemented \cite{Tang2009}. A dramatic change to the architecture could mean a greater number of people who are affected by that change.  The people who are affected may have to revise their understanding of the new structure even if it still performs the same function as before.   It also requires the intervention of an architect and assumes that there is if not one right way to represent code that should be chosen and agreed upon. Taylor et al. claims that there will always be the need for design \cite{Taylor2007}. What this view overlooks however is that a different perspective or different design may be better suited to a different task. Even Taylor et al. spends quite some time discussing different perspectives and paradigms but does not develop this further into an understanding that there could be equivalently well designed artefacts for the same purpose that differ \cite{Taylor2007}.
%@nonl
%@-node:hasletpara.20130910094414.1578:Archetecture
%@+node:hasletpara.20131031084746.1626:Big ball of mud
\subsection{Big Ball of Mud}
According to Foote throwaway code is a major cause for the most often coded Big Ball of Mud pattern \cite{Foote1997}. Some of this could be made worse by source control merges not being able to identify the throwaway code. In practice these are normally marked with a comment to manually indicate that this code is irrelivant or temporary and needs revision. The source control system is not aware about these comments and does not identify the throwaway code. Quick and dirty fixes can make their way from branches into the main stream without being checked to see if they are wanted.
%@nonl
%@-node:hasletpara.20131031084746.1626:Big ball of mud
%@+node:hasletpara.20131115102112.1758:Code equivlency
\subsection{Code Equivalence}
The ability to detect code that has the same functionality is especially relevant to this thesis. Park et al. have suggested one way that this could be achieved however this may be too course grained \cite{Park2013}. Park suggests using some very basic rules to eliminate items in the compared source code that have very little impact on how the program functions. An example would be changing all string arguments ("string") into empty strings ("") before comparing the code. This requires ignoring items that could be relevant later. Using Parks method still may be a good initial step to determine if code blocks underwent large structural changes. The semi-semantic merge suggested by Le{\ss}nich and Apel may be a better approach \cite{LeBenich2012} \cite{Apel2011}.
%@nonl
%@-node:hasletpara.20131115102112.1758:Code equivlency
%@+node:hasletpara.20130910094414.1579:Design patterns
\subsection{Design patterns}
Design patterns are another way which has been used to identify the best code for a particular issue. Due to the dynamic nature of source code however it may be useful to consider different design patterns for differing tasks. Designing according to patterns without making a clear judgement call about if the pattern is necessary could lead to a condition Kerievsky calls ``Patterns Happy'' \cite{Kerievsky2004}. This refers to code as being over-engineered. This means there could still be some dispute about the correct pattern to use in a certain situation. Therefore it is possible for code to diverge even if patterns are used.
%@nonl
%@-node:hasletpara.20130910094414.1579:Design patterns
%@+node:hasletpara.20130910094414.1581:Model Driven Development
%@-node:hasletpara.20130910094414.1581:Model Driven Development
%@+node:hasletpara.20130910094414.1583:Mviews
\subsection{MViews}
MViews as described by Grundy is a way to focus on a small subsection of code in a more graphical way \cite{Grundy1993}. This is of interest to us because it is similar to having two independent views of the code. Refactoring could change a number of widely separated files. This makes it harder to see if such a tool could be used to show two views that have entirely the same functionality have been refactored differently. 
%@nonl
%@-node:hasletpara.20130910094414.1583:Mviews
%@+node:hasletpara.20131105141303.1629:reuse
\subsection{Reuse}
Another reason you may want to diverge from a point is when the code is being reused. Tracz claims that often it needs to be refactored to fit in with the new code \cite{Tracz1995}. Once it has been refactored any further changes in the original code need to be manually propagated. Normally this is how you would expect a typical reuse scenario if the code can be used without the refactoring. If we consider one form of reuse being the use of library package however sometimes when the library package updates the programmer may want to use the new library. Having the ability to make updating a smaller block of code smoother in spite of it being refactored may be desirable. 
%@nonl
%@-node:hasletpara.20131105141303.1629:reuse
%@+node:hasletpara.20130910094414.1582:version control
\subsection{Version Control} 
A way to maintain divergent code that is currently being used is version control. According to Bertino it is possible to keep a smaller more easily deployed repository it is necessary to evaluate what is necessary and what is unnecessary \cite{Bertino2012}. Although Bertino refers to unnecessary files this premise may also be applicable for the smaller blocks of code we are interested in. This suggests that maintaining a record about what is relevant and what is irrelevant may have some benefit. Version control still can have merge conflict issues. These issues have a far greater chance of occurring if there is a dramatic change such as refactoring. By using a semi-semantic merge as proposed by Apel these issues can be reduced \cite{Apel2011}. The idea of a refactoring aware version control is not new as Freese also proposed a prototype eclipse plug-in for making the version control aware about refactoring code \cite{Freese2006}. What this paper will investigate is if by maintaining information about equivalency relationships and by examining the changes between subsequent check-ins if merge conflicts are further reduced. 
%@-node:hasletpara.20130910094414.1582:version control
%@+node:hasletpara.20130910094414.1580:Well Documented Code
%@-node:hasletpara.20130910094414.1580:Well Documented Code
%@-others
%@nonl
%@-node:hasletpara.20130905084546.1653:Related Work
%@+node:hasletpara.20130905084546.1652:Proposed Approach
\section{Proposed Approach}
%@<<maintaining reletionship>>
%@+node:hasletpara.20131122093500.1826:<<maintaining reletionship>>
The ability to represent similar functionality in two different ways could allow developers to refactor for different purposes. Maintaining relationships between the refactored views may reduce the impact of merging two divergent branches. 


Evidence of this could be found by a reduced number of conflicts. What this could mean for developers in a multi-developer environment is that the branch of code that they work on could be in a more consistent state. This would hopefully reduce the time spent trying to comprehend changes that another developer has made.
%@nonl
%@-node:hasletpara.20131122093500.1826:<<maintaining reletionship>>
%@nl

%@<<how to maintain functional equilvilence>>
%@+node:hasletpara.20131122093500.1829:<<how to maintain functional equilvilence>>
Being able to provide manual instructions and hints about how the source control should treat set blocks of code needs investigation. If a record is kept of conflicting items that are marked as being functionally equivalent they do not need to be included in merge. The simplest of these would be comments that have been marked as being functionally irrelevant. If there is a conflict with the comment in one branch with a line of code in another branch, their could be an indication about which should be preferred. Another reason to mark something as functionally irrelevant might be if there is throwaway code that you do not want propagated over your whole version control system.
%@nonl
%@-node:hasletpara.20131122093500.1829:<<how to maintain functional equilvilence>>
%@nl

%@<<Implemenatation>>
%@+node:hasletpara.20131122093500.1838:<<Implemenatation>>
%@<<annotations>>
%@+node:hasletpara.20131122093500.1830:<<annotations>>
One way of identify functionally equivalent code would be to use annotations in the source file as indicators. A unique key would possibly be required if the block of code was functionally equivalent to differing code in other branches. A different annotation may need to be used to indicate that items such as code for debugging purposes, throwaway code or comments specific to a view are not merged. The benefit of this is that it can eliminate unnecessary merging when either the code has been marked as having same intention or if the code is irrelevant in other branches.
%@nonl
%@-node:hasletpara.20131122093500.1830:<<annotations>>
%@nl

%@<<seperate branch>>
%@+node:hasletpara.20131122093500.1831:<<seperate branch>>
A way to keep track of irrelevant code would be to create a third branch which only pulls down changes and is never used to commit changes. Although this would be suitable for the situation where there was throwaway code, comments or debugging it would be harder to maintain without additional tooling. It would also be harder to manually identify equivalent code segments that do not need to be merged.
%@nonl
%@-node:hasletpara.20131122093500.1831:<<seperate branch>>
%@nl

%@<<leverage JDime>>
%@+node:hasletpara.20131122093500.1832:<<leverage JDime>>
There is already some refactoring aware merge tools that have been researched. An example would be the ''JDime'' system proposed by Apel \cite{Apel2011}. Most of these however, are general purpose and have been created as difference or merge tools that can be plugged into various version control systems. What this could mean is that using the progressive changes in a distributed system has not been explored.
%@nonl
%@-node:hasletpara.20131122093500.1832:<<leverage JDime>>
%@nl

%@<<merge git and Jdime>>
%@+node:hasletpara.20131122093500.1833:<<merge git and Jdime>>
The proposed approach is to look at the code associated with Git and JDime and figure out how we can relate each step in git to a merge. Using JDime and Git as a starting point see anything can be gained by using the additional steps rather than just merging the top items in a single merge . This should not be as computationally expensive as it sounds if the semi-structured approach set forward by Le{\ss}nich and Apel should mean that this is only necessary for conflicting items \cite{LeBenich2012} \cite{Apel2011}. By merging some of the refactoring aware functionaility of JDime with GIT we plan to further reduce the amount of merge conflicts. 
%@nonl
%@-node:hasletpara.20131122093500.1833:<<merge git and Jdime>>
%@nl
%@nonl
%@-node:hasletpara.20131122093500.1838:<<Implemenatation>>
%@nl

%@<<Testing>>
%@+node:hasletpara.20131122093500.1837:<<Testing>>
%@<<planned method of test>>
%@+node:hasletpara.20131122093500.1834:<<planned method of test>>
This paper will test view that being able to automatically discern and manually mark items as being related between two will reduce the amount of conflicts that occur. Initially the automatic marking all comments as being irrelevant will be tested. The results will be compared against the ''JDime'' system without any additional features. As things progress this could give us a clearer indication about what things could be manually marked as being equivalent.
%@nonl
%@-node:hasletpara.20131122093500.1834:<<planned method of test>>
%@nl

%@<<Variable names>>
%@+node:hasletpara.20131122093500.1835:<<Variable names>>
One of the things that will be investigated is if the changing of variable or method names is possible. This is going to be a challenge as if the method is or variable is not private or local the use of it could be spread over a number of files. For this reason initially only private methods, private variables and local variables will be considered. Investigation needs to be done to see if some of these changes are already covered by ''JDime''.
%@nonl
%@-node:hasletpara.20131122093500.1835:<<Variable names>>
%@nl

%@<<testing on checkins>>
%@+node:hasletpara.20131122093500.1836:<<testing on checkins>>
This project will also test if there are any advantages in comparing on a check-in by check-in basis rather than simply comparing the most recent check-in for two branches against each other. Again this will be done by examining if the total amount of conflicts can be reduced. Some of the conflicts will also be manually examined to see if they are simpler or more simply resolved using this process. This could identify if the maintenance of the version control system could be simplified.
%@nonl
%@-node:hasletpara.20131122093500.1836:<<testing on checkins>>
%@nl
%@nonl
%@-node:hasletpara.20131122093500.1837:<<Testing>>
%@nl
%@-node:hasletpara.20130905084546.1652:Proposed Approach
%@-others
%@-node:hasletpara.20130905084546.1632:<<body>>
%@nl

%@<<bibliography>>
%@+node:hasletpara.20130905084546.1649:<<bibliography>>
\bibliography{Thesis}
\bibliographystyle{agsm}
%@nonl
%@-node:hasletpara.20130905084546.1649:<<bibliography>>
%@nl

\end{document}



%@-node:hasletpara.20130905084546.1629:@shadow ./fmpp/Tex/Proposal.tex
%@-leo
